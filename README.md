# PDF_chatbot_ollama
It's a PDF chatbot which can answer any ques related to the PDF.


###Let me give you the overview of this project:

Let's walk through the **complete breakdown** of your project â€” a **PDF chatbot using Streamlit, LangChain, and Ollama** â€” including the libraries used, architecture, steps, and important details to fully understand and manage it.

---

## ğŸ”§ Project Overview

Youâ€™ve built a **PDF Chatbot** that lets users upload a PDF and ask questions about its content using a local LLM (e.g., TinyLLaMA) via Ollama. This is powered by:

* **Streamlit**: Web UI framework.
* **LangChain**: Framework to chain LLMs with tools like retrievers and memory.
* **Ollama**: Local LLM runtime (TinyLLaMA or other models).
* **PyMuPDF / fitz**: Extract text from PDF files.

---

## ğŸ“¦ Libraries Used & What They Do

| Library                                         | Role                                                               |
| ----------------------------------------------- | ------------------------------------------------------------------ |
| `streamlit`                                     | Create the web interface for file upload and chat                  |
| `langchain`                                     | Create chains of LLM calls with context (retrievers, chains)       |
| `langchain_community.llms.ollama`               | LangChain wrapper to connect to Ollama models                      |
| `PyMuPDF (fitz)`                                | Extracts text from PDF documents                                   |
| `tiktoken` or `langchain.text_splitter`         | Token-based text chunking                                          |
| `faiss` / `chromadb` / `langchain.vectorstores` | Store vector embeddings for semantic search (if using vectorstore) |
| `ollama` (CLI tool)                             | Downloads and serves local models like TinyLLaMA                   |
| `dotenv` / `os`                                 | Load secrets, if needed                                            |
| `typing`                                        | Type hinting for better code clarity                               |

---

## ğŸ§  Architecture Diagram

```
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Streamlit â”‚   â† User Uploads PDF / Asks Question
       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Extract Text (fitz)â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Split Text into Chunks     â”‚
 â”‚ (LangChain TextSplitter)    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Convert Chunks â†’ Embeddings (Optional)â”‚
 â”‚ Store in Vector DB (FAISS / Chroma)   â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Ask LLM via LangChain â†’ Ollamaâ”‚ â† using TinyLLaMA
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Answer   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§± Step-by-Step Breakdown

### 1. **Set Up Ollama and Pull the Model**

```bash
ollama pull tinyllama
ollama run tinyllama
```

This runs a local REST API server on `localhost:11434`.

---

### 2. **Install Python Dependencies**

```bash
pip install streamlit langchain langchain-community PyMuPDF
```

Optionally, install FAISS if youâ€™re using vector search:

```bash
pip install faiss-cpu
```

---

### 3. **Extract Text from PDF**

Using PyMuPDF:

```python
import fitz

def extract_text_from_pdf(pdf_file):
    doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
    text = ""
    for page in doc:
        text += page.get_text()
    return text
```

---

### 4. **Split Text into Chunks**

This helps the model handle long documents:

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
texts = splitter.create_documents([full_text])
```

---

### 5. **Vector Embedding and Search (Optional)**

If you're using semantic search:

```python
from langchain.vectorstores import FAISS
from langchain.embeddings import OllamaEmbeddings

embeddings = OllamaEmbeddings(model='tinyllama')
db = FAISS.from_documents(texts, embeddings)
retriever = db.as_retriever()
```

---

### 6. **LangChain LLM Setup with Ollama**

```python
from langchain_community.llms import Ollama

llm = Ollama(model="tinyllama")  # Make sure model is pulled
```

---

### 7. **LangChain QA Chain**

```python
from langchain.chains.question_answering import load_qa_chain

chain = load_qa_chain(llm, chain_type="stuff")  # or "map_reduce" for larger docs
answer = chain.run({'context': text, 'question': user_input})
```

---

### 8. **Streamlit App UI**

```python
import streamlit as st

st.title("PDF Chatbot with TinyLLaMA")

pdf = st.file_uploader("Upload a PDF", type="pdf")
if pdf:
    text = extract_text_from_pdf(pdf)
    question = st.text_input("Ask a question about the PDF")
    if question:
        answer = chain.run({'context': text, 'question': question})
        st.write("Answer:", answer)
```

---

## ğŸ§ª Testing & Debugging Tips

* â— **404 error** from Ollama? Make sure model is pulled (`ollama pull tinyllama`)
* ğŸ§  **Too long context error**? Reduce chunk size or use summarization
* ğŸ’¥ **TypeError / unhashable list**? Check your `List` usage, especially in `middlewares`

---

## ğŸš€ Enhancements You Can Add Later

| Feature       | Description                        |
| ------------- | ---------------------------------- |
| Memory        | Use conversation history           |
| Summarization | Add auto-summarize button          |
| PDF Search    | Add search for keywords            |
| Multiple PDFs | Let user chat across documents     |
| UI polish     | Add sidebar, spinner, themes, etc. |

---

## ğŸ“ Folder Structure (Suggested)

```
pdf-chatbot/
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ ollama-models/
â”‚   â””â”€â”€ pulled models (local)
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ pdf_utils.py (extraction etc.)
```

---

## âœ… Final Thoughts

Iâ€™ve built a **local privacy-safe chatbot** that can read any document and answer questions â€” powered by lightweight models like TinyLLaMA, without needing OpenAI API keys.

